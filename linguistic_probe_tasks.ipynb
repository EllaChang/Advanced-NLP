{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"linguistic_probe_tasks.ipynb","provenance":[{"file_id":"1nuaVF4CKMdPHEGrhSOharj_X7MAs_VcS","timestamp":1603668356669},{"file_id":"1kvbZA5m8B53BzPJABazaX2Ko_RGN0wVZ","timestamp":1574311539338},{"file_id":"10X2uqKvRCPZIeyjzaTBlA7l2LIBHZPX2","timestamp":1574299894529},{"file_id":"11SbXXQdw7VvFOF2CbsLMRdbcT20yA4W6","timestamp":1573435042333},{"file_id":"1ndA77K345-h4p63-YeG2YmTox7x24GgD","timestamp":1573427729773},{"file_id":"1g3a9fxRXCVIJD09-uEbswf4RQ22Aenlh","timestamp":1555525814496},{"file_id":"1Qvw5AJbcZXcPrkwM2nQp5zV00eM1aj0j","timestamp":1554308449053}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"75ea_6eKOtV4"},"source":["# CS585: Homework 3"]},{"cell_type":"markdown","metadata":{"id":"R-iQqZR4Oy82"},"source":["**This HW is due on Dec 5th, 2019, submitted via Gradescope as a PDF (File > Print > Save as PDF). 90 points total.**\n","\n","\n","**IMPORTANT**: After copying this notebook to your Google Drive, please add a link to it below. To get a publicly-accessible link, hit the Share button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this homework!\n","LINK: **paste your link here**\n","\n","\n","\n","##### How to do this problem set:\n","\n","- Most of these questions require writing Python code and computing results, and the rest of them have textual answers. To generate the answers, you will have to fill out all code-blocks that say `ENTER CODE HERE`.\n","\n","- For all of the textual answers you have to write your answers under placeholder text which says  `Enter your answers here` \n"," \n","- Some experiments make take long to run (those involving ELMO and BERT), so **start early**! \n","\n","##### How to submit this problem set:\n","- Write all the answers in this ipython notebook. Once you are finished (1) Generate a PDF via (File -> Print -> Save as PDF) and upload to Gradescope.\n","  \n","- **Important:** check your PDF before you turn it in to Gradescope to make sure it exported correctly. If Colab gets confused about your syntax, it will sometimes terminate the PDF creation routine early.\n","\n","- When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. Then you'll be sure it's actually right. One handy way to do this is by clicking `Runtime -> Run All` in the notebook menu.\n","\n","##### Academic honesty \n","\n","- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your PDF. If you turn in correct answers on your PDF without code that actually generates those answers, we will consider this a serious case of cheating. See the course page for honesty policies.\n","\n","- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n","\n","To get started, first run the following cell to create a PyDrive client and download data to your own Google Drive.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NQeKo5BBLpNm"},"source":["### Overview\n","In this homework, we will be studying probe tasks. Probe tasks are special tasks designed to interpret neural networks (especially, deep networks or word embeddings in NLP). Probe tasks generally use simple classifiers and special datasets to analyze the linguistic content stored in dense representations.\n","\n","We will also use this assignment to learn AllenNLP (https://github.com/allenai/allennlp), an excellent tool to build deep models for NLP and seamlessly integrate pretrained word embeddings.\n","(NOTE - This assignment is written using `allennlp` as a Python library. A faster way of using `allennlp` is via JSONNET configuration files, as described [here](https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/walk_through_allennlp/configuration.md). However, learning to use AllenNLP as a library is essential when you want to write custom AllenNLP modules. [This](https://allennlp.org/tutorials) is a good tutorial on using AllenNLP as a library.)\n","\n","Let's start by setting up Google Drive to download data.\n","\n","(*Run the cell below. No need to edit any code here.*)"]},{"cell_type":"code","metadata":{"id":"The2yi02jscj"},"source":["!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BhHo6LZPrqN"},"source":["### Install AllenNLP\n","\n","Run the below cell once per session to install `allennlp` locally. You might need to restart the runtime after doing this. No need to re-run it for a different runtime in the same session.\n","\n","(*Run the cell below. No need to edit any code here.*)"]},{"cell_type":"code","metadata":{"id":"cjRB5xxFOoZh"},"source":["# can take about a minute\n","!pip install allennlp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93Hzae6bP3w1"},"source":["### Subject-Verb Agreement\n","\n","In this assignment, we will design a probe task to test whether word embeddings capture subject-verb agreement. For instance, in English we use the singular verb in this sentence,\n","\n","\n","*   CORRECT - This assignment **is** very easy.\n","*   WRONG - This assignment **are** very easy.\n","\n","Subject-Verb agreement is an important probe task in NLP literature (see [Linzen et al. 2016](https://arxiv.org/abs/1611.01368) and [Gulordova et al. 2018](https://arxiv.org/abs/1803.11138)). We will be using the evaluation set described in  [Linzen et al. 2016](https://arxiv.org/abs/1611.01368), but formulating the problem in a different way.\n","\n","We start by downloading our dataset. Each `inp` variable represents an English sentence. Each `out` variable has four parts, a) index of verb b) correct verb form c) wrong verb form d) number of agreement attractors (we will not need this data for our experiments, but you should read about them in [Linzen et al. 2016](https://arxiv.org/abs/1611.01368) to help you explain some of the results we obtain).\n","\n","(*Run the cell below. No need to edit any code here.*)\n"]},{"cell_type":"code","metadata":{"id":"9P4IoAcQzjn1"},"source":["import pickle\n","\n","f_agreement = drive.CreateFile({'id': '1S1_RQQHTwwf0F6IM2MmbIr4inINyNbsQ'})\n","f_agreement.GetContentFile('./agreement.pkl') \n","\n","\n","with open('./agreement.pkl', 'rb') as f_in:\n","    agreement_inp, agreement_output = pickle.load(f_in)\n","\n","\n","agreement_inp = agreement_inp.strip().split('\\n')\n","agreement_output = agreement_output.strip().split('\\n')\n","\n","data_points = [(inp, out) for inp, out in zip(agreement_inp, agreement_output)]\n","print(\"Length of all data = %d\" % len(data_points))\n","\n","# Splitting into 10%-15% train-valid splits. We are not using the full dataset for computational reasons.\n","# We take a small training dataset since we want to assess the linguistic knowledge stored in pretrained embeddings.\n","len_data = len(data_points)\n","train_data = data_points[0 : int(0.1 * len_data)]\n","valid_data = data_points[int(0.1 * len_data) : int(0.25 * len_data)]\n","# Actual dataset sizes will be two times this, both the positive and negative example of these sentences\n","print(\"train, valid data lengths = %d, %d\" % (len(train_data), len(valid_data)))\n","# print(train_data)\n","print(train_data[1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMu4St9OUVkv"},"source":["### AllenNLP DatasetReader\n","We next write a `DatasetReader` in `allennlp`, which is essentially a PyTorch `DatasetReader` with some syntactic sugar. The use of `Field` objects is essential to allow seamless padding and integration with rest of the `allennlp` pipeline.\n","\n","We will model our probe task as a binary classification task, where given an input sentence, a network has to determine whether the subject-verb agreement is correct or wrong. Notice how we generate two data points per sentence  in the `_read()` function, one with the correct verb (labelled `\"correct\"`) and the other with the wrong verb (labelled `\"wrong\"`).\n","\n","(*Run the cell below. No need to edit any code here.*)"]},{"cell_type":"code","metadata":{"id":"h96J8X8Fh4qh"},"source":["import allennlp\n","from allennlp.data.dataset_readers import DatasetReader\n","\n","from allennlp.data import Instance\n","from allennlp.data.fields import TextField, LabelField\n","\n","from allennlp.data.token_indexers import TokenIndexer\n","from allennlp.data.tokenizers import Token\n","\n","from allennlp.data.vocabulary import Vocabulary\n","\n","from typing import Iterator, List, Dict\n","\n","class AgreementDatasetReader(DatasetReader):\n","    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:\n","        super().__init__(lazy=False)\n","        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n","\n","    def text_to_instance(self, tokens: List[str], label: str) -> Instance:\n","        tokens = [Token(x) for x in tokens]\n","        fields = {\n","            \"sentence\": TextField(tokens, self.token_indexers),\n","            \"labels\": LabelField(label)\n","        }\n","        return Instance(fields)\n","\n","    def _read(self, dataset) -> Iterator[Instance]:\n","        for inp, out in dataset:\n","            correct_input = [x for x in inp.split()[:-1]]\n","            position, correct, wrong, _ = out.split('\\t')\n","            position = int(position)\n","            # verifying whether input is in correct form\n","            assert correct_input[position] == correct.lower()\n","            # yield both the correct and wrong forms of the agreement\n","            wrong_input = [x for x in correct_input]\n","            wrong_input[position] = wrong.lower()\n","            \n","            yield self.text_to_instance(correct_input, \"correct\")\n","            yield self.text_to_instance(wrong_input, \"wrong\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uBWTOqrnVgRC"},"source":["### Question 1.1 - AllenNLP Model (20 points)\n","\n","We will now build a simple one-layer classifer on top of average-pooled embeddings.  Notice how the `word_embeddings` are passed as a parameter to the model. This helps abstract the word embeddings outside the model, so it is very simple to swap random vectors with word2vec, GloVE, ELMo or BERT (as we will do in this exercise).\n","\n","Implement the `forward()` function for this model. Make sure you implement masking correctly, to avoid including masked vectors in the average pooling.\n","\n","(*Implement the missing sections in the code below. This is the only code you need to implement, so be careful!*)"]},{"cell_type":"code","metadata":{"id":"AC9yxSuVi9Nd"},"source":["# requires code\n","import torch\n","from allennlp.models import Model\n","from allennlp.modules.text_field_embedders import TextFieldEmbedder\n","from allennlp.training.metrics import CategoricalAccuracy\n","from allennlp.nn.util import get_text_field_mask\n","\n","class AgreementProbeTask(Model):\n","    def __init__(self,\n","                 word_embeddings: TextFieldEmbedder,\n","                 vocab: Vocabulary) -> None:\n","        super().__init__(vocab)\n","        self.word_embeddings = word_embeddings\n","\n","        self.final_linear = torch.nn.Linear(\n","            in_features=word_embeddings.get_output_dim(),\n","            out_features=vocab.get_vocab_size('labels')\n","        )\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        self.accuracy = CategoricalAccuracy()\n","\n","    def forward(self,\n","                sentence: Dict[str, torch.Tensor],\n","                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n","\n","        mask = get_text_field_mask(sentence)\n","        embeddings = self.word_embeddings(sentence)\n","\n","        # obtain a single vector for each element of the minibatch from the embeddings matrix\n","        if 'bert' in self.word_embeddings._token_embedders:\n","            # For BERT, we use the first token [CLS] for classification\n","            # construct logits using the first embedding vector of the sequence only\n","            #\n","            # ENTER CODE HERE 1\n","            pass\n","        else:\n","            # For other models, we will average the embeddings across the sequence dimension\n","            # Use the `mask` variable to correctly normalize the sum of embeddings by the sequence lengths\n","            #\n","            # ENTER CODE HERE 2\n","            pass\n","\n","                        \n","        \n","        # Use the linear layer declared in __init__ to construct the logits\n","        # \n","        # ENTER CODE HERE 3\n","        pass\n","\n","        output = {\"logits\": None}\n","\n","        if labels is not None:\n","            self.accuracy(logits, labels)\n","            output[\"loss\"] = self.criterion(logits, labels)\n","\n","        return output\n","    \n","    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n","        return {\"accuracy\": self.accuracy.get_metric(reset)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6iqZKhxBT99z"},"source":["### A Primer on Fine-Tuning\n","\n","Before we analyze some word embeddings, we should understand some terminology (used in rest of the assignment). While using pre-trained weights for a downstream task, typically two approaches are used - 1) they are kept constant during the training 2) they optimized jointly with the rest of the network on the downstream task objective. The first approach (we will call this **frozen embeddings**) saves training cost and is arguably a better indicator of the native linguistic knowledge stored in the original embeddings. The second approach (we will call this **tunable embeddings**) generally leads to the best performance on the downstream task, but often suffers from catastrophic forgetting.\n","\n","It is an open research problem to fully understand the cases where fine-tuning word embeddings is useful.  [Peters et al. 2019](https://arxiv.org/abs/1903.05987) is a recent research paper on this topic."]},{"cell_type":"markdown","metadata":{"id":"RVbmONVWS6-Q"},"source":["### Putting the Pieces Together ...\n","\n","The code below is an implementation of the training infrastructure in AllenNLP, specific to our application. For the rest of the assignment, you only need to worry about modifying `config` and explaining the results you get. Run the cell below once to register the functions.\n","\n","*(Run the cell below. No need to edit any code here.)*"]},{"cell_type":"code","metadata":{"id":"3pa97L8s7Tcf"},"source":["from allennlp.modules.token_embedders import (\n","    Embedding,\n","    ElmoTokenEmbedder,\n","    PretrainedBertEmbedder\n",")\n","from allennlp.modules.token_embedders.embedding import _read_pretrained_embeddings_file\n","from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n","from allennlp.data.iterators import BucketIterator\n","from allennlp.training.trainer import Trainer\n","\n","from allennlp.data.token_indexers import (\n","    SingleIdTokenIndexer,\n","    ELMoTokenCharactersIndexer,\n","    PretrainedBertIndexer\n",")\n","\n","import logging\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger()\n","\n","def reset_weights_fn(m):\n","    if hasattr(m, \"reset_parameters\"):\n","        m.reset_parameters()\n","\n","def run_experiment(config):\n","    embedding_type = config['embedding_type']\n","    embedding_size = config['embedding_size']\n","    urls = config['urls']\n","    tunable = config['tunable']\n","    batch_size = config['batch_size']\n","    num_epochs = config['num_epochs']\n","    reset_weights = config['reset_weights']\n","    \n","    # A token indexer is necessary to inform the DatasetReader the indexing process\n","    if embedding_type in ['random', 'glove']:\n","        logger.info(\"Using a single ID token indexer...\")\n","        token_indexers = {\n","            'tokens': SingleIdTokenIndexer()\n","        }\n","\n","    elif embedding_type == 'elmo':\n","        logger.info(\"Using elmo character token indexer...\")\n","        token_indexers = {\n","            'elmo': ELMoTokenCharactersIndexer()\n","        }\n","\n","    elif embedding_type == 'bert':\n","        logger.info(\"Using bert token indexer...\")\n","        token_indexers = {\n","            'bert': PretrainedBertIndexer('bert-base-uncased')\n","        } \n","\n","    else:\n","        logger.info(\"Invalid embeddings type, quitting...\")\n","        return\n","\n","    # Loading training and validation datasets via our reader\n","    reader = AgreementDatasetReader(token_indexers)\n","    train_dataset = reader.read(train_data)\n","    valid_dataset = reader.read(valid_data)\n","    # `vocab` contains both the input vocab and output label space\n","    vocab = Vocabulary.from_instances(train_dataset + valid_dataset)\n","\n","    if embedding_type == 'random':\n","        logger.info(\"Using random embeddings...\")\n","        token_embedding = Embedding(\n","            num_embeddings=vocab.get_vocab_size('tokens'),\n","            embedding_dim=embedding_size,\n","            trainable=tunable\n","        )\n","        word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n","\n","    elif embedding_type == 'glove':\n","        logger.info(\"Using glove embeddings...\")\n","        weight = _read_pretrained_embeddings_file(\n","            urls[0],\n","            embedding_size,\n","            vocab\n","        )\n","        token_embedding = Embedding(\n","            num_embeddings=vocab.get_vocab_size('tokens'),\n","            weight=weight,\n","            embedding_dim=embedding_size,\n","            trainable=tunable\n","        )\n","        word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})   \n","\n","    elif embedding_type == 'elmo':\n","        logger.info(\"Using elmo embeddings...\")\n","        elmo_token_embedding = ElmoTokenEmbedder(\n","            urls[0], urls[1], dropout=0, requires_grad=tunable\n","        )\n","        if reset_weights is True:\n","            logger.info(\"Resetting elmo weights...\")\n","            \n","            elmo_token_embedding.apply(reset_weights_fn)\n","        word_embeddings = BasicTextFieldEmbedder({\"elmo\": elmo_token_embedding})\n","    \n","    elif embedding_type == 'bert':\n","        logger.info(\"Using bert embeddings...\")\n","        bert_token_embedding = PretrainedBertEmbedder(\n","            'bert-base-uncased', requires_grad=tunable\n","        )\n","        if reset_weights is True:\n","            logger.info(\"Resetting bert weights...\")\n","            bert_token_embedding.apply(reset_weights_fn)\n","        word_embeddings = BasicTextFieldEmbedder(\n","            {\"bert\": bert_token_embedding},\n","            {\"bert\": ['bert']},\n","            allow_unmatched_keys=True\n","        )\n","\n","    else:\n","        logger.info(\"Invalid embeddings type, quitting...\")\n","        return\n","\n","\n","    model = AgreementProbeTask(word_embeddings, vocab)\n","    \n","    if torch.cuda.is_available():\n","        cuda_device = 0\n","        model = model.cuda(cuda_device)\n","    else:\n","        cuda_device = -1\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    # A bucket iterator is needed to sort the data by sequence length and reduce padding overhead\n","    iterator = BucketIterator(batch_size=batch_size,\n","                              sorting_keys=[(\"sentence\", \"num_tokens\")])\n","    iterator.index_with(vocab)\n","\n","    # This function wraps all the whole training loop into a single object\n","    trainer = Trainer(model=model,\n","                      optimizer=optimizer,\n","                      iterator=iterator,\n","                      train_dataset=train_dataset,\n","                      validation_dataset=valid_dataset,\n","                      patience=20,\n","                      validation_metric='+accuracy',\n","                      num_epochs=num_epochs,\n","                      cuda_device=cuda_device)\n","    return trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Ooop9x9DJE3"},"source":["###  Question 1.2 - GloVE Embeddings (20 points)\n","\n","We are ready to train our model! We will start by training a baseline classification model which will use GLoVE embeddings. We will test both cases where the GLoVE embeddings are trainable and fixed. \n","\n","1. Try varying the embedding size (50, 100, 300) and report **early stopping** validation accuracy in the text box below. AllenNLP will provide this information to you at the end of training. Keep the embeddings frozen.\n","2. Next, report the performance for tunable embeddings.\n","3. Explain your observations / trends. What do you notice about training time / number of epochs across different runs? You are encouraged to think critically about the trends you notice in this question and the following questions. Most of the points awarded will depend on your explanations.\n","\n","(NOTE - The loss and accuracy values are in a similar range in some parts of this assignment, read the logs carefully!)\n","\n","*Hint - As a verification of your implementation, your 300 dimensional tunable accuracy should about 61%. This could vary slightly due to stochasticity.*\n","\n","\n","The three sizes of GloVE embeddings that we are going to use can be found here -\n","\n","\n","*  50 dimensional = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.50d.txt.gz\n","*  100 dimensional = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n","*  300 dimensional = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.840B.300d.txt.gz\n","\n","**For your reference, the largest GloVe setting (300, tunable) takes about 3 minutes 30 seconds to finish finetuning**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KON2Vth8bWlZ"},"source":["### Enter your answers here\n","\n","\n","**Frozen Embeddings**  \n","50 dimensional = \n","\n","100 dimensional =  \n","\n","300 dimensional =  \n","\n","\n","\n","\n","**Tunable Embeddings**  \n","50 dimensional =  \n","\n","100 dimensional =  \n","\n","300 dimensional =  \n","\n","**Explain your results here**\n","\n"]},{"cell_type":"code","metadata":{"id":"MvQuWDP6Q89-"},"source":["config = {\n","    'embedding_type': 'glove',\n","    'embedding_size': 50,\n","    'urls': [\n","        'https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.50d.txt.gz'\n","    ],\n","    'tunable': True,\n","    'batch_size': 100,\n","    'num_epochs': 100,\n","    'reset_weights': False\n","}\n","run_experiment(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0oVb5-e9LKck"},"source":["###  Question 1.3 - Contextualized Word Embeddings - ELMo (20 points)\n","\n","Having studied standard word embeddings, we are now going to explore modern sentence embedding techniques such as ELMo.\n","\n","1. Run the model with frozen and tunable ELMo embeddings and report the **early stopping** validation accuracy results as in Question 1.2.\n","2. Run a baseline ELMo model with randomly initialized weights (Use the `reset_weights` configuration) and report the results. Consider both settings - frozen embeddings and tunable embeddings.\n","3. Explain your results, compare it with GloVE embeddings. Why was this model so slow?\n","\n","**For your reference, the worst case of ELMo finetuning (random weights, tunable) takes about 1 hour and 20 minutes.**"]},{"cell_type":"markdown","metadata":{"id":"OYGmO-lskZl1"},"source":["### Enter your answers here\n","\n","\n","\n","**Frozen Embeddings**  \n","random weights =  \n","\n","pretrained weights = \n","\n","\n","\n","**Tunable Embeddings**  \n","random weights =  \n","\n","pretrained weights = \n","\n","\n","**Explain your results here**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"TaQkdCdkzIe2"},"source":["config = {\n","    'embedding_type': 'elmo',\n","    'embedding_size': 1024,\n","    'urls': [\n","        'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json',\n","        'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n","    ],\n","    'tunable': True,\n","    'batch_size': 100,\n","    'num_epochs': 100,\n","    'reset_weights': True\n","}\n","\n","run_experiment(config)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CetK-QJtOGZZ"},"source":["###  Question 1.4 - Contextualized Word Embeddings - BERT (20 points)\n","\n","As our final step, we will analyze representations learnt from BERT.\n","\n","1. Run the model with frozen BERT embeddings and report the **early stopping** validation accuracy as earlier.\n","2. Run a baseline BERT model with randomly initialized weights (Use the `reset_weights` configuration). Consider only the frozen weight setting.\n","3. Explain your results, compare it with GloVE and ELMo embeddings. Why was this faster (or slower) than ELMo?\n","\n","\n","\n","(Note - Fine-tuning BERT was crashing colab, probably due to a memory error. Feel free to check if this is the case and find any workarounds for this. Maybe, vary the batch_size)\n","\n","**For your references, finetuning BERT with randomly initialized weights takes about 30 minutes**"]},{"cell_type":"markdown","metadata":{"id":"j0pHd3M6CE3e"},"source":["### Enter your answers here\n","\n","\n","\n","\n","\n","**Frozen Embeddings**  \n","random weights =    \n","\n","pretrained weights = \n","\n","\n","**Explain your results here**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"REeaWr4ROS9P"},"source":["config = {\n","    'embedding_type': 'bert',\n","    'embedding_size': 768,\n","    'urls': [],\n","    'tunable': False,\n","    'batch_size': 100,\n","    'num_epochs': 100,\n","    'reset_weights': False\n","}\n","run_experiment(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKxB-wFlN4ec"},"source":["###  Question 1.5 - Sentence Composition (10 points)\n","\n","One drawback of our analysis was the word embedding aggregation algorithm (averaging) used to build the sentence embedding was lossy. Is there a better way to aggregate sentences to avoid being lossy and improve the performance of frozen embedding models? (Please give at least three solutions to get full credits)\n","\n","### Enter your answer here\n","\n","\n","\n","<br>\n"]},{"cell_type":"code","metadata":{"id":"XFWBVj-QGumb"},"source":[""],"execution_count":null,"outputs":[]}]}